---
---

@inproceedings{santos2024aiaa,
    author = {Santos, Jamie and Dinkel, Holly and Di, Julia and Borges, Paulo V.K. and Gouveia Moreira, Marina and Coltin, Brian and Smith, Trey},
    year = {2024},
    booktitle={{AIAA SciTech Forum}},
    title = {{Unsupervised Change Detection for Space Habitats Using 3D Point Clouds}},
    month = {1},
    abstract = {Autonomous robotic systems are needed to help maintain spacecraft and space habitats on future long-duration deep-space missions, such as the Gateway space station, which will be uncrewed for extended periods. In this work, we propose an algorithm for scene change detection from raw point clouds to enable autonomous robotic caretaking, using the International Space Station (ISS) as an analog of future space habitats. Currently deployed on the ISS, the Astrobee assistive free-flyer robot uses change detection software to inspect, identify anomalies, and update maps. However, the existing ISS scene analysis software relies on manually-labeled images for detecting changes. In contrast, the algorithm presented in this work eliminates the need for highly manual data annotation by using only raw point clouds as inputs, and is not sensitive to the category of changed objects. From two input point clouds, our algorithm performs change detection using Gaussian Mixture Model (GMM) clustering. Through experiments conducted in a granite table mockup of the ISS at NASA Ames Research Center, we successfully demonstrate the detection of new objects, disappearing objects, and multiple scene changes. To promote further research and development, the source code and benchmarking data are publicly released.},
    preview = {aiaa2024gt.png},
    selected={true}
}

@inproceedings{ta2023sim,
    author = {Ta*, Minh Quang and Dinkel*, Holly and Abdul-Rashid, Hameed and Dai, Yangfei and Myers, Jessica and Chen, Tan and Geng, Junyi, and Bretl, Timothy},
    year = {2023},
    booktitle={{IEEE/RSJ IROS Workshop on Robotics and AI in Future Factory (RAFF)}},
    title = {{The Impact of Time Step Frequency on the Realism of Robotic Manipulation Simulation for Objects of Different Scales}},
    month = {10},
    abstract = {This work evaluates the impact of time step frequency and component scale on robotic manipulation simulation accuracy. Increasing the time step frequency for small-scale objects is shown to improve simulation accuracy. This simulation, demonstrating pre-assembly part picking for two object geometries, serves as a starting point for discussing how to improve Sim2Real transfer in robotic assembly processes.},
    pdf = {IROS2023.pdf},
    poster = {ICRA2023RMDO_poster.pdf},
    video = {https://www.youtube.com/watch?v=JOXrBpMmI0A},
    preview = {real2sim_comparison.png},
    selected={true}
}

@article{xiang2023trackdlo,
  title = {{TrackDLO: Tracking Deformable Linear Objects Under Occlusion with Motion Coherence}},
  author = {Xiang, Jingyi and Dinkel, Holly and Zhao, Harry and Gao, Naixiang and Coltin, Brian and Smith, Trey and Bretl, Timothy},
  journal={IEEE Robotics and Automation Letters},
  year = {2023},
  month={8},
  volume={8},
  number={10},
  pages={6179-6186},
  doi={10.1109/LRA.2023.3303710},
  abstract = {The TrackDLO algorithm estimates the shape of a Deformable Linear Object (DLO) under occlusion from a sequence of RGB-D images. TrackDLO is vision-only and runs in real-time. It requires no external state information from physics modeling, simulation, visual markers, or contact as input. The algorithm improves on previous approaches by addressing three common scenarios which cause tracking failure: tip occlusion, mid-section occlusion, and self-occlusion. This is achieved through the application of Motion Coherence Theory to impute the spatial velocity of occluded nodes, the use of the topological geodesic distance to track self-occluding DLOs, and the introduction of a non-Gaussian kernel that only penalizes lower-order spatial displacement derivatives to reflect DLO physics. Improved real-time DLO tracking under mid-section occlusion, tip occlusion, and self-occlusion is demonstrated experimentally. The source code and demonstration data are publicly released.},
  pdf = {https://ieeexplore.ieee.org/document/10214157},
  code = {https://github.com/RMDLO/trackdlo},
  preview = {trackdlo_preview.png},
  video = {https://youtu.be/MxqNJsen5eg},
  selected={true}
}

@inproceedings{xiang2023multidlo,
    author = {Xiang, Jingyi and Dinkel, Holly},
    year = {2023},
    booktitle={{IEEE ICRA Workshop on Representing and Manipulating Deformable Objects}},
    title = {{Simultaneous Shape Tracking of Multiple Deformable Linear Objects with Global-Local Topology Preservation}},
    month = {May},
    abstract = {This work presents an algorithm for tracking the shape of multiple entangling Deformable Linear Objects (DLOs) from a sequence of RGB-D images. This algorithm runs in real-time and improves on previous single-DLO tracking approaches by enabling tracking of multiple objects. This is achieved using Global-Local Topology Preservation (GLTP). This work uses the geodesic distance in GLTP to define the distance between separate objects and the distance between different parts of the same object. Tracking multiple entangling DLOs is demonstrated experimentally. The source code is publicly released. },
    pdf = {ICRA2023RMDO_paper.pdf},
    code = {https://github.com/RMDLO/multi-dlo},
    preview = {multidlo.png},
    video = {https://youtu.be/hfiqwMxitqA},
    poster = {ICRA2023RMDO_poster.pdf},
    selected={true}
}

@inproceedings{dinkel2023iac,
    author = {Dinkel*, Holly and Di*, Julia and Santos, Jamie and Albee, Keenan and Borges, Paulo V.K. and Gouveia Moreira, Marina and Alexandrov, Oleg and Coltin, Brian and Smith, Trey},
    year = {2023},
    booktitle={{IAF International Astronautical Congress}},
    title = {{Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity with Free-Flying Robots}},
    month = {3},
    abstract = {Assistive free-flyer robots autonomously caring for future crewed outposts---such as NASAâ€™s Astrobee robots on the International Space Station (ISS)---must be able to detect day-to-day interior changes to track inventory, detect and diagnose faults, and monitor the outpost status. This work presents a framework for multi-agent cooperative mapping and change detection to enable robotic maintenance of space outposts. One agent is used to reconstruct a 3D model of the environment from sequences of images and corresponding depth information. Another agent is used to periodically scan the environment for inconsistencies against the 3D model. Change detection is validated \textit{a posteriori} using real image and pose data collected by Astrobee robots in a ground testbed environment and from microgravity aboard the ISS. This work outlines the objectives, requirements, and algorithmic modules for the multi-agent reconstruction system, including recommendations for its use by assistive free-flyers aboard future microgravity outposts.},
    preview = {iac2023.png},
    pdf = {IAC2023.pdf},
    selected={true}
}

@inproceedings{dinkel2022iac,
    author = {Dinkel*, Holly and Cornelius*, Jason},
    year = {2022},
    booktitle={{IAF International Astronautical Congress}},
    title = {{Vela: A Data-Driven Proposal for Joint Collaboration in Space Exploration}},
    month = {9},
    abstract = {The UN Office of Outer Space Affairs identifies synergy of space development activities and international cooperation through data and infrastructure sharing in their Sustainable Development Goal 17 (SDG17). Current multilateral space exploration paradigms, however, are divided between the Artemis and the Roscosmos-CNSA programs to return to the moon and establish permanent human settlements. As space agencies work to expand human presence in space, economic resource consolidation in pursuit of technologically ambitious space expeditions is the most sensible path to accomplish SDG17. This paper compiles a budget dataset for the top five federally-funded space agencies: CNSA, ESA, JAXA, NASA, and Roscosmos. Using time-series econometric anslysis methods in STATA, this work analyzes each agency's economic contributions toward space exploration. The dataset results are used to propose a multinational space mission, Vela, for the development of an orbiting space station around Mars in the late 2030s. Distribution of economic resources and technological capabilities by the respective space programs are proposed to ensure programmatic redundancy and increase the odds of success on the given timeline.},
    pdf = {IAC2022.pdf},
    supp = {IAC2022_presentation.pdf},
    preview = {lvs.png},
    selected={true}
}

@inproceedings{dinkel2022glex,
    author = {Cornelius, Jason and Dinkel, Holly and Kurgan, Arzu},
    year = {2021},
    booktitle={{IAF Global Space Exploration Conference (GLEX)}},
    title = {{Development of a Private Space Sector in the U.S. and Russia}},
    month = {6},
    abstract = {This work analyzes progress and challenges in the development of commercial space economies in the United States and Russia. Space development progress is characterized through examination of three production indicators for the space economies in each country and econometric analysis of the financial data for three new American private space companies. We also provide case studies of major challenges faced by three new private space companies and conjecture about the future of the private space industry through analysis of space education projects in each country. As leaders of space technological development and exploration, the U.S. and Russia are major stakeholders in the current and future global space economy. We find access to capital is a primary barrier to entrepreneurship. The results will help future founders more effectively navigate the complex financial, regulatory, and technological landscape of the space industry.},
    pdf = {GLEX2021.pdf},
    preview = {LaunchPlot.PNG},
    video = {https://youtu.be/xt2uH0qKv9s},
    selected={true}
}

@inproceedings{dinkel2022RMDOO,
    author = {Dinkel*, Holly and Xiang*, Jingyi and Zhao, Harry and Coltin, Brian and Smith, Trey and Bretl, Timothy},
    year = {2022},
    booktitle={{IEEE ICRA Workshop on Representing and Manipulating Deformable Objects}},
    title = {{Wire Point Cloud Instance Segmentation from RGBD Imagery with Mask R-CNN}},
    month = {5},
    abstract = {Perception of the shapes of deforming objects like wires enables their monitoring and manipulation by autonomous robots. This paper presents detection, classification, and instance segmentation of deformable wires from a cluttered scene in RGBD imagery. This work uses the Detectron2 implementation of Mask R-CNN trained with the PointRend mask head on the UIUCWires dataset as the framework for wire instance segmentation on RGB imagery, a method demonstrated to perform well for the instance segmentation task in previous work. In this work, the instance bitmask is directly used to segment individual object point clouds, an important step toward wire shape representation for manipulation tasks.},
    pdf = {https://deformable-workshop.github.io/icra2022/spotlight/WDOICRA2022_08.pdf},
    preview = {wire_segmentation.png},
    video = {https://youtu.be/eqgZQckCDOY},
    selected={true}
}

@inproceedings{chen2022insights,
    author = {Chen, Tan and Huang, Zhe and Motes, James and Geng, Junyi and Ta, Quang Minh and Dinkel, Holly and Abdul-Rashid, Hameed and Myers, Jessica and Mun, Ye-Ji and Lin, Wei-Che and Huang, Yuan-Yung and Liu, Sizhe and Morales, Marco and Amato, Nancy and Driggs-Campbell, Katherinte and Bretl, Timothy},
    year = {2022},
    booktitle={{IEEE ICRA Workshop on Collaborative Robots and Work of the Future}},
    title = {{Insights from an Industrial Collaborative Assembly Project: Lessons in Research and Collaboration}},
    month = {5},
    abstract = {Significant progress in robotics reveals new opportunities to advance manufacturing. Next-generation industrial automation will require both integration of distinct robotic technologies and their application to challenging industrial environments. This paper presents lessons from a collaborative assembly project between three academic research groups and an industry partner. The goal of the project is to develop a flexible, safe, and productive manufacturing cell for sub-centimeter precision assembly. Solving this problem in a high-mix, low-volume production line motivates multiple research thrusts in robotics. This work identifies new directions in collaborative robotics for industrial applications and offers insight toward strengthening collaborations between institutions in academia and industry on the development of new technologies.},
    pdf = {https://drive.google.com/file/d/1tRxx4vOb0SXX8LnQ3WeduaBud7eStDYO/view},
    preview = {wotf.png},
    video = {https://drive.google.com/file/d/1Vce93zH5N1a0dci7OP_YU3OjusJUVI_n/view},
    selected={true}
}

@inproceedings{yonehara2016gas,
    author = {Yonehara, Katsuya and Abrams, Robert and Dinkel, Holly and Freemire, Ben and Johnson, Rolland and Kazakevich, Grigory and Tollestrup, Alvin and Zwaska, Robert},
    year = {2016},
    booktitle={{International Particle Accelerator Conference}},
    title = {{Gas Filled RF Resonator Hadron Beam Monitor for Intense Neutrino Beam Experiments}},
    month = {6},
    abstract = {MW-class beam facilities are being considered all over the world to produce an intense neutrino beam for fundamental particle physics experiments. A radiation-robust beam monitor system is required to diagnose the primary and secondary beam qualities in high-radiation environments. We have proposed a novel gas-filled RF-resonator hadron beam monitor in which charged particles passing through the resonator produce ionized plasma that changes the permittivity of the gas. The sensitivity of the monitor has been evaluated in numerical simulation. A signal manipulation algorithm has been designed. A prototype system will be constructed and tested by using a proton beam at the MuCool Test Area at Fermilab.},
    pdf = {https://www.osti.gov/servlets/purl/1280866},
    preview = {beam_monitor.png},
    selected={true}
}